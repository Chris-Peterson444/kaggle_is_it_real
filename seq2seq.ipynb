{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data import Field, BucketIterator\n",
    "import torchtext\n",
    "\n",
    "import spacy\n",
    "\n",
    "import sys, os, io, time, random, math\n",
    "import numpy as numpy\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer Setup\n",
    "I am using spaCy to tokenize since it's a little more robust than the default pytorch tokenizer\n",
    "Seq2Seq reverses the input sentences, but since this techincally is more semantic analysis\n",
    "than sequence to sequence, we're going to leave it in the forward order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_en = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_input_lang(text):\n",
    "    '''\n",
    "    Tokenize input from a string into a list of tokens and reverses it\n",
    "    '''\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fields setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrissyp/anaconda3/envs/christmas/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "TEXT = Field(tokenize = tokenize_input_lang, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "LABEL = Field(dtype = torch.int)\n",
    "# The original file contains: id    keyword    location    target\n",
    "# However I haven't decided how I want to include the keywords in this model yet (probably concatentaiton)\n",
    "# So for now it is being trained without\n",
    "#\n",
    "# To train with\n",
    "fields = [(None, None), (None, None), (None,None), ('text', TEXT), ('label', LABEL)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Loading Data To Use In PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrissyp/anaconda3/envs/christmas/lib/python3.7/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/home/chrissyp/anaconda3/envs/christmas/lib/python3.7/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "twitter_dataset = torchtext.data.TabularDataset('train.csv','csv',fields,skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchtext.data.split() returns default a 70-30 split for training-testin\n",
    "# but since testing is provided by kaggle we will treat this as our \n",
    "# training-validation split\n",
    "train_data, valid_data = twitter_dataset.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double check we've loaded the right number and split correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total examples: 7613\n",
      "Number of training examples: 5329\n",
      "Number of validation examples: 2284\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of total examples: {len(twitter_dataset.examples)}\")\n",
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of one of the training data (Tokenized correctly and reversed (?) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['so', 'i', 'pick', 'myself', 'off', 'the', 'ground', 'and', 'swam', 'before', 'i', 'drowned', '.', 'hit', 'the', 'bottom', 'so', 'hard', 'i', 'bounced', 'twice', 'suffice', 'this', 'time', 'around', 'is', 'different', '.'], 'label': ['1']}\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[1]))\n",
    "print(type(vars(train_data.examples[1])['label'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slang Embeddings setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/542320 [00:00<?, ?it/s]Skipping token b'542320' with 1-dimensional vector [b'300']; likely a header\n",
      "100%|██████████| 542320/542320 [00:44<00:00, 12129.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# def load_embeddings(fname):\n",
    "#     fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "#     n, d = map(int, fin.readline().split())\n",
    "#     data = {}\n",
    "#     for line in fin:\n",
    "#         tokens = line.rstrip().split(' ')\n",
    "#         data[tokens[0]] = list(map(float, tokens[1:]))\n",
    "#     return data\n",
    "\n",
    "# slang_emb = load_embeddings('ud_embeddings/ud_basic.vec')\n",
    "slang_emb = torchtext.vocab.Vectors(name = 'ud_embeddings/ud_basic.vec',\n",
    "                                   cache = 'ud_embeddings',\n",
    "                                   unk_init = torch.Tensor.normal_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some helpful functions to verify things are working correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next block from https://colab.research.google.com/github/bentrevett/pytorch-sentiment-analysis/blob/master/B%20-%20A%20Closer%20Look%20at%20Word%20Embeddings.ipynb#scrollTo=DMkoy7iFMeN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(embeddings, word):\n",
    "    assert word in embeddings.stoi, f'*{word}* is not in the vocab!'\n",
    "    return embeddings.vectors[embeddings.stoi[word]]\n",
    "\n",
    "def closest_words(embeddings, vector, n = 10):\n",
    "    \n",
    "    distances = [(word, torch.dist(vector, get_vector(embeddings, word)).item())\n",
    "                 for word in embeddings.itos]\n",
    "    \n",
    "    return sorted(distances, key = lambda w: w[1])[:n]\n",
    "\n",
    "def print_tuples(tuples):\n",
    "    for w, d in tuples:\n",
    "        print(f'({d:02.04f}) {w}') \n",
    "        \n",
    "\n",
    "def analogy(embeddings, word1, word2, word3, n=5):\n",
    "    \n",
    "    #get vectors for each word\n",
    "    word1_vector = get_vector(embeddings, word1)\n",
    "    word2_vector = get_vector(embeddings, word2)\n",
    "    word3_vector = get_vector(embeddings, word3)\n",
    "    \n",
    "    #calculate analogy vector\n",
    "    analogy_vector = word2_vector - word1_vector + word3_vector\n",
    "    \n",
    "    #find closest words to analogy vector\n",
    "    candidate_words = closest_words(embeddings, analogy_vector, n+3)\n",
    "    \n",
    "    #filter out words already in analogy\n",
    "    candidate_words = [(word, dist) for (word, dist) in candidate_words \n",
    "                       if word not in [word1, word2, word3]][:n]\n",
    "    \n",
    "    print(f'{word1} is to {word2} as {word3} is to...')\n",
    "    \n",
    "    return candidate_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ma is to actor as woman is to...\n",
      "(5.9133) actress\n",
      "(6.1269) actors\n",
      "(6.2390) actrivist\n",
      "(6.2655) grimepp\n",
      "(6.2856) mayim\n"
     ]
    }
   ],
   "source": [
    "print_tuples(analogy(slang_emb, 'man', 'actor', 'woman'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data,\n",
    "                vectors = slang_emb)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in text vocabulary: 17668\n",
      "Unique tokens in label vocabulary: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in text vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in label vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterator setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrissyp/anaconda3/envs/christmas/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_iterator, valid_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder from LSTM (Context vectors) + fully connected layer to predict sentiment\n",
    "\n",
    "The Encoder is based on Sew2Seq tutorial https://colab.research.google.com/github/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb#scrollTo=Ao4yzOdnyv8s. \n",
    "\n",
    "Much of this math and logic will come from there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use a 2 layer LSTM for our encoder. If I have time I would like to do like Seq2Seq and do a 4 layer\n",
    "\n",
    "### Starting with simple RNN structure\n",
    "\n",
    "Consider the input sequence $X$ where $x_t \\in X$ is the input token to the first encoder layer at time t, and the hidden states $H = \\{h_1, h_2, ..., h_T\\}$ are the output a hidden layer. Also let $e(x)$ represent the embedding of the input token $x$. Then with superscripts representing the layer, we can consider our input functions as\n",
    "\n",
    "$$h_t^1 = \\text{EncoderRNN}^1(e(x_t),h^1_{t-1})$$\n",
    "and\n",
    "$$h_t^2 = \\text{EncoderRNN}^2(h^1_t,h^2_{t-1})$$\n",
    "\n",
    "Let the initial hidden state as input for each layer be $h_0^l$ and the final context vector per layer be $z^l = h_T^l$\n",
    "\n",
    "### Transforming into LSTM\n",
    "\n",
    "We think about LSTM's being simple extensions from RNN's by adding an extra cell state an extra 'hidden state', although they have different functions. We denote this $c_t^l$ Our simple input function:\n",
    "\n",
    "$$h_t = \\text{RNN}(e(x_t), h_{t-1})$$\n",
    "\n",
    "can then be transformed into\n",
    "\n",
    "$$ (h_t, c_t) = \\text{LSTM}(e(x_t), h_{t-1}, c_{t-1})$$\n",
    "\n",
    "We'll also need an initial cell state $c_0^l$ and we will transform our context-vector/final-hidden-state to be the tupple $z^l = (h_T^l, c_T^l)$.\n",
    "\n",
    "By extension to two layers then we have \n",
    "\n",
    "$$\\begin{align*}\n",
    "(h_t^1, c_t^1) &= \\text{EncoderLSTM}^1(e(x_t), (h_{t-1}^1, c_{t-1}^1))\\\\\n",
    "(h_t^2, c_t^2) &= \\text{EncoderLSTM}^2(h_t^1, (h_{t-1}^2, c_{t-1}^2))\n",
    "\\end{align*}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected\n",
    "\n",
    "Small fully connected layer to help with encapsulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self, hid_dim, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \n",
    "        return self.fc_out(input.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, encoder, fc, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.fc = fc\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        output = self.fc(hidden)\n",
    "       \n",
    "        return output\n",
    "     \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insantiate everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "ENC_EMB_DIM = 300\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "fc = FullyConnected(HID_DIM,OUTPUT_DIM)\n",
    "\n",
    "model = CustomModel(enc,fc, device ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize weights\n",
    "\n",
    "We're going to initialize all weights from a uniform distribution between -0.08 and +0.08 (like in the seq2seq paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(17668, 300)\n",
       "    (rnn): LSTM(300, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (fc): FullyConnected(\n",
       "    (fc_out): Linear(in_features=512, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Info about the number of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 9,070,772 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
